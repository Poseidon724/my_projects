{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A778DI6lRT9Q"
   },
   "source": [
    "**Feature Engineering Task 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "VnBEJVGnLa8E",
    "outputId": "d0ff67c8-9c9b-43f3-b6aa-7df76ef4add7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "564    1\n",
      "565    1\n",
      "566    1\n",
      "567    1\n",
      "568    0\n",
      "Name: diagnosis, Length: 569, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/9ncd60nx1c5d_qq20fr0pck80000gp/T/ipykernel_61058/4072820184.py:22: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  mean_value = data[column].replace(0, pd.np.nan).mean()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data from a CSV file\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data.to_csv(\"editedData.csv\")\n",
    "\n",
    "# Iterate through each column\n",
    "for column in data.columns:\n",
    "    # Check if the column has any missing or zero values\n",
    "    if data[column].isna().sum() + (data[column] == 0).sum() > 0:\n",
    "        # Check if the column is categorical\n",
    "        if data[column].dtype == 'object':\n",
    "            # Impute missing and zero values with the most frequent value\n",
    "            mode_value = data[column].mode()[0]\n",
    "            data[column].fillna(mode_value, inplace=True)\n",
    "            data[column] = data[column].replace(0, mode_value)\n",
    "           # print(\"Column '{}' has been updated. Missing or zero values before: {}. Missing or zero values after: {}. Imputed with value: {}\".format(column, data[column].isna().sum() + (data[column] == 0).sum(), data[column].isna().sum() + (data[column] == 0).sum(), mode_value))\n",
    "        # Otherwise, assume it's a continuous numerical value\n",
    "        else:\n",
    "            # Impute missing and zero values with the mean value\n",
    "            mean_value = data[column].replace(0, pd.np.nan).mean()\n",
    "            data[column].fillna(mean_value, inplace=True)\n",
    "            data[column] = data[column].replace(0, mean_value)\n",
    "          #  print(\"Column '{}' has been updated. Missing or zero values before: {}. Missing or zero values after: {}. Imputed with value: {}\".format(column, data[column].isna().sum() + (data[column] == 0).sum(), data[column].isna().sum() + (data[column] == 0).sum(), mean_value))\n",
    "\n",
    "# Save the updated data to the original CSV file\n",
    "\n",
    "data[\"diagnosis\"] = (data[\"diagnosis\"] ==\"M\").astype(int)\n",
    "data.to_csv(\"editedData.csv\", index=False)\n",
    "\n",
    "# Print the updated data\n",
    "print(data[\"diagnosis\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqOvk_qBRTH4"
   },
   "source": [
    "**Feature Engineering Task 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "k67BTzfIHQjj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load the dataset as a Pandas DataFrame\n",
    "df = pd.read_csv('editedData.csv')\n",
    "# extract the numeric columns except the first two columns and convert to a Numpy array\n",
    "numeric_cols = df.iloc[:, 2:].select_dtypes(include=[np.number]).columns\n",
    "dataset = df[numeric_cols].values\n",
    "\n",
    "# calculate the mean and standard deviation of each feature\n",
    "mu = np.mean(dataset, axis=0)\n",
    "sigma = np.std(dataset, axis=0)\n",
    "\n",
    "# apply feature normalization\n",
    "normalized_dataset = (dataset - mu) / sigma\n",
    "\n",
    "# update the original DataFrame with the normalized values\n",
    "df.loc[:, numeric_cols] = normalized_dataset\n",
    "\n",
    "# save the normalized dataset back to the normData.csv file\n",
    "df.to_csv('normData.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46Z9BDbPRi4a"
   },
   "source": [
    "**Part A - Perceptron Learning Algorithm:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wz8zQ_xFRnW_"
   },
   "source": [
    "***Learning Task 1: ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "aIPdieyyR4DQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PM1 accuracy: 0.9202127659574468\n",
      "PM2 accuracy: 0.8936170212765957\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "data = pd.read_csv('editedData.csv')\n",
    "data = data.drop('id', axis=1)  # Drop the id column\n",
    "train_data = data.sample(frac=0.67, random_state=1)  # Randomly select 67% of the data for training\n",
    "test_data = data.drop(train_data.index)  # Use the remaining data for testing\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, lr=0.01, epochs=50):\n",
    "        self.weights = np.zeros(input_size)\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def predict(self, x):\n",
    "        z = np.dot(x, self.weights)\n",
    "        return np.where(z > 0, 1, 0)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(X.shape[0]):\n",
    "                y_pred = self.predict(X[i])\n",
    "                error = y[i] - y_pred\n",
    "                self.weights += self.lr * error * X[i]\n",
    "def evaluate(model, test_data):\n",
    "    X_test = test_data.iloc[:, 1:].values\n",
    "    y_test = test_data.iloc[:, 0].values\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    return accuracy\n",
    "\n",
    "pm1 = Perceptron(input_size=train_data.shape[1]-1)\n",
    "pm1.train(train_data.iloc[:, 1:].values, train_data.iloc[:, 0].values)\n",
    "pm1_acc = evaluate(pm1, test_data)\n",
    "print(f\"PM1 accuracy: {pm1_acc}\")\n",
    "\n",
    "pm2 = Perceptron(input_size=train_data.shape[1]-1)\n",
    "train_data = train_data.sample(frac=1)  # Shuffle the training data\n",
    "pm2.train(train_data.iloc[:, 1:].values, train_data.iloc[:, 0].values)\n",
    "pm2_acc = evaluate(pm2, test_data)\n",
    "print(f\"PM2 accuracy: {pm2_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfHmKjkHfJKe"
   },
   "source": [
    "Here we have define the perceptron algorithm\n",
    "Then, we have define a function to evaluate the performance of the model on the test set:\n",
    "Now, we can use the perceptron algorithm to train two models (PM1 and PM2) by changing the order of training examples:\n",
    "We can observe that PM1 and PM2 have different accuracies. This is because the order of training examples affects the final weights of the model.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQuDaEz83aS3"
   },
   "source": [
    "**Task 2: Building Perceptron Model PM3 on Normalized Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IEh1w_7JiAb4",
    "outputId": "11087b91-08be-4af0-c6e7-e9d03f49c0ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PM3 accuracy on normalized data: 0.973404255319149\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, lr=0.01, epochs=50):\n",
    "        self.weights = np.zeros(input_size)\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def predict(self, x):\n",
    "        z = np.dot(x, self.weights)\n",
    "        return np.where(z > 0, 1, 0)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(X.shape[0]):\n",
    "                y_pred = self.predict(X[i])\n",
    "                error = y[i] - y_pred\n",
    "                self.weights += self.lr * error * X[i]\n",
    "def evaluate(model, test_data):\n",
    "    X_test = test_data.iloc[:, 1:].values\n",
    "    y_test = test_data.iloc[:, 0].values\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    return accuracy\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('normData.csv')\n",
    "data = data.drop('id', axis=1)  # Drop the id column\n",
    "train_data1 = data.sample(frac=0.67, random_state=1)\n",
    "test_data1 = data.drop(train_data.index)\n",
    "\n",
    "# Train PM3 on normalized data\n",
    "pm3 = Perceptron(input_size=train_data1.shape[1]-1)\n",
    "pm3.train(train_data1.iloc[:, 1:].values, train_data1.iloc[:, 0].values)\n",
    "pm3_acc = evaluate(pm3,test_data1)\n",
    "print(f\"PM3 accuracy on normalized data: {pm3_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rC2rOwAYfjDC"
   },
   "source": [
    "Here, we used the normalised training data to train the PM3 model and the normalised testing data to assess its performance. Due to the normalised data, we can see that PM3 has a different accuracy than PM1 and PM2. As a result, we now know that normalised models provide more accuracy than unnormalized ones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk_IePPC3o4B"
   },
   "source": [
    "**Task 3: Building Perceptron Model PM4 on Randomly Permutated Features**\n",
    "\n",
    "To build PM4, we will randomly permute the order of features in the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8wMOhVAfnnv"
   },
   "source": [
    "Here, we used the sample approach to shuffle the columns (features) of the training data, and we then trained the PM4 model using the shuffled training data. Only the features with weights greater than zero in the PM4 model were used to evaluate its performance using the testing data. This is due to the fact that the weights of the other features were set to zero at initialization and stayed that way throughout the training procedure. Due to the randomly permuted characteristics, we can see that PM4 has a different accuracy than PM1, PM2, and PM3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kS5kbZVQnNMx",
    "outputId": "29b60908-0c9b-4187-cb4a-c1928568efe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PM4 Accuracy: 0.9202127659574468\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, lr=0.01, epochs=50):\n",
    "        self.weights = np.zeros(input_size)\n",
    "        self.lr = lr\n",
    "        self.epochs =   epochs\n",
    "\n",
    "    def predict(self, x):\n",
    "        z = np.dot(x, self.weights)\n",
    "        return np.where(z > 0, 1, 0)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(X.shape[0]):\n",
    "                y_pred = self.predict(X[i])\n",
    "                error = y[i] - y_pred\n",
    "                self.weights += self.lr * error * X[i]\n",
    "def evaluate(model, test_data):\n",
    "    X_test = test_data.iloc[:, 1:].values\n",
    "    y_test = test_data.iloc[:, 0].values\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    return accuracy\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('editedData.csv')\n",
    "\n",
    "# Drop id column\n",
    "data = data.drop('id', axis=1)\n",
    "\n",
    "train_data = data.sample(frac=0.67, random_state=1)\n",
    "test_data = data.drop(train_data.index)\n",
    "\n",
    "\n",
    "# Randomly permute feature order\n",
    "np.random.seed(1)\n",
    "perm = np.random.permutation(train_data.shape[1]-1) + 1\n",
    "train_data_permuted = train_data.iloc[:, np.concatenate(([0], perm))]\n",
    "\n",
    "# Train PM4 on permuted data\n",
    "pm4 = Perceptron(input_size=train_data_permuted.shape[1]-1)\n",
    "pm4.train(train_data_permuted.iloc[:, 1:].values, train_data_permuted.iloc[:, 0].values)\n",
    "\n",
    "\n",
    "merged_test_data = pd.concat([test_data.iloc[:, 0], test_data.iloc[:, perm]], axis=1)\n",
    "num_columns1 = data.shape[1]\n",
    "num_columns2 = train_data.shape[1]\n",
    "num_columns3 = test_data.shape[1]\n",
    "\n",
    "# print(\"Number of columns in data :\", num_columns1)\n",
    "# print(\"Number of columns in train data :\", num_columns2)\n",
    "# print(\"Number of columns in test_data :\", num_columns3)\n",
    "\n",
    "num_columns = merged_test_data.shape[1]\n",
    "\n",
    "#print(\"Number of columns in merged data :\", num_columns)\n",
    "\n",
    "merged_test_data.to_csv('test.csv', index=False)\n",
    "\n",
    "pm4_acc = evaluate(pm4, merged_test_data)\n",
    "print(\"PM4 Accuracy:\", pm4_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZmmmgFKeJli"
   },
   "source": [
    "**Accuracy of 10 random samples for PM1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lCsr01PeN4K",
    "outputId": "2563c2b6-9279-4e46-a942-76b921cf305c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PM1 accuracy: 0.8882978723404256\n",
      "PM1 accuracy: 0.9414893617021277\n",
      "PM1 accuracy: 0.9414893617021277\n",
      "PM1 accuracy: 0.8617021276595744\n",
      "PM1 accuracy: 0.925531914893617\n",
      "PM1 accuracy: 0.9095744680851063\n",
      "PM1 accuracy: 0.898936170212766\n",
      "PM1 accuracy: 0.8829787234042553\n",
      "PM1 accuracy: 0.8829787234042553\n",
      "PM1 accuracy: 0.898936170212766\n",
      "Mean accuracy: 0.90319149\n",
      "Standard deviation: 0.02503958\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, lr=0.01, epochs=50):\n",
    "        self.weights = np.zeros(input_size)\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def predict(self, x):\n",
    "        z = np.dot(x, self.weights)\n",
    "        return np.where(z > 0, 1, 0)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(X.shape[0]):\n",
    "                y_pred = self.predict(X[i])\n",
    "                error = y[i] - y_pred\n",
    "                self.weights += self.lr * error * X[i]\n",
    "def evaluate(model, test_data):\n",
    "    X_test = test_data.iloc[:, 1:].values\n",
    "    y_test = test_data.iloc[:, 0].values\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('editedData.csv')\n",
    "data = data.drop('id', axis=1)  # Drop the id column\n",
    "\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "for i in range(10):\n",
    "    train_data = data.sample(frac=0.67, random_state=np.random.randint(1,100))  # Randomly select 67% of the data for training\n",
    "    test_data = data.drop(train_data.index)  # Use the remaining data for testing\n",
    "\n",
    "    pm1 = Perceptron(input_size=train_data.shape[1]-1)\n",
    "    pm1.train(train_data.iloc[:, 1:].values, train_data.iloc[:, 0].values)\n",
    "    pm1_acc = evaluate(pm1, test_data)\n",
    "    print(f\"PM1 accuracy: {pm1_acc}\")\n",
    "    accuracies.append(pm1_acc)\n",
    "\n",
    "print(f\"Mean accuracy: {np.mean(accuracies):.8f}\")\n",
    "print(f\"Standard deviation: {np.std(accuracies):.8f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VegBBuWscgTX"
   },
   "source": [
    "**Accuracy of 10 random samples for PM3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7P4Nler2cfNa",
    "outputId": "7a3b200f-c6d4-498d-cc76-34b0ea24dcf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9946808510638298\n",
      "0.9893617021276596\n",
      "0.9787234042553191\n",
      "0.9893617021276596\n",
      "0.9787234042553191\n",
      "0.9787234042553191\n",
      "0.9893617021276596\n",
      "0.9893617021276596\n",
      "0.9893617021276596\n",
      "0.9787234042553191\n",
      "Mean accuracy: 0.98563830\n",
      "Standard deviation: 0.00585106\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, lr=0.01, epochs=50):\n",
    "        self.weights = np.zeros(input_size)\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def predict(self, x):\n",
    "        z = np.dot(x, self.weights)\n",
    "        return np.where(z > 0, 1, 0)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(X.shape[0]):\n",
    "                y_pred = self.predict(X[i])\n",
    "                error = y[i] - y_pred\n",
    "                self.weights += self.lr * error * X[i]\n",
    "def evaluate(model, test_data):\n",
    "    X_test = test_data.iloc[:, 1:].values\n",
    "    y_test = test_data.iloc[:, 0].values\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    return accuracy\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('normData.csv')\n",
    "data = data.drop('id', axis=1)  # Drop the id column\n",
    "accuracies = []\n",
    "for i in range(10):\n",
    "    train_data1 = data.sample(frac=0.67, random_state=np.random.randint(1,100))\n",
    "    test_data1 = data.drop(train_data.index)\n",
    "\n",
    "    # Train PM3 on normalized data\n",
    "    pm3 = Perceptron(input_size=train_data1.shape[1]-1)\n",
    "    pm3.train(train_data1.iloc[:, 1:].values, train_data1.iloc[:, 0].values)\n",
    "    pm3_acc = evaluate(pm3,test_data1)\n",
    "    print(pm3_acc)\n",
    "    accuracies.append(pm3_acc)\n",
    "\n",
    "print(f\"Mean accuracy: {np.mean(accuracies):.8f}\")\n",
    "print(f\"Standard deviation: {np.std(accuracies):.8f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hyc0kHYTMBS"
   },
   "source": [
    "**Average accuracy for 10 random samples: PM4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSE-G0ZPTKAL",
    "outputId": "4607294a-21c4-4abb-97de-3eca125f41bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9042553191489362\n",
      "0.8882978723404256\n",
      "0.8882978723404256\n",
      "0.8882978723404256\n",
      "0.8882978723404256\n",
      "0.8882978723404256\n",
      "0.8882978723404256\n",
      "0.8882978723404256\n",
      "0.8882978723404256\n",
      "0.8882978723404256\n",
      "Mean accuracy: 0.88989362\n",
      "Standard deviation: 0.00478723\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('editedData.csv')\n",
    "\n",
    "# Drop id column\n",
    "data = data.drop('id', axis=1)\n",
    "accuracies = []\n",
    "for i in range(10):\n",
    "    # data = data.sample(frac=1)\n",
    "    train_data = data.sample(frac=0.67, random_state=np.random.randint(1,100))\n",
    "    test_data = data.drop(train_data.index)\n",
    "    # split the data into training and testing sets\n",
    "  \n",
    "\n",
    "    # Randomly permute feature order\n",
    "    np.random.seed(1)\n",
    "    perm = np.random.permutation(train_data.shape[1]-1) + 1\n",
    "    train_data_permuted = train_data.iloc[:, np.concatenate(([0], perm))]\n",
    "\n",
    "    # Train PM4 on permuted data\n",
    "    pm4 = Perceptron(input_size=train_data_permuted.shape[1]-1)\n",
    "    pm4.train(train_data_permuted.iloc[:, 1:].values, train_data_permuted.iloc[:, 0].values)\n",
    "\n",
    "\n",
    "    merged_test_data = pd.concat([test_data.iloc[:, 0], test_data.iloc[:, perm]], axis=1)\n",
    "    #merged_test_data = pd.concat([test_data.iloc[:, 0], test_data.iloc[:, np.concatenate(([0], perm))]], axis=1)\n",
    "\n",
    "\n",
    "    pm4_acc = evaluate(pm4, merged_test_data)\n",
    "    print(pm4_acc)\n",
    "    accuracies.append(pm4_acc)\n",
    "\n",
    "print(f\"Mean accuracy: {np.mean(accuracies):.8f}\")\n",
    "print(f\"Standard deviation: {np.std(accuracies):.8f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
