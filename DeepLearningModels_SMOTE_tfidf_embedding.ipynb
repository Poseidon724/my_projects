{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIrQrUavpzk5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./logs/"
      ],
      "metadata": {
        "id": "oFkHRtr_qEef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import pandas as pd\n",
        "train_df=pd.read_csv('gdrive/My Drive/NLP_Project/train_data_SMOTE.csv')\n",
        "train_df=train_df.drop(columns=train_df.columns[0])\n",
        "\n",
        "test_df=pd.read_csv('gdrive/My Drive/NLP_Project/test_data_SMOTE.csv')\n",
        "test_df=test_df.drop(columns=test_df.columns[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVh99sQMqmei",
        "outputId": "0f19a848-6150-4e74-99dc-7e16d80b1591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=train_df.iloc[:,:-1]\n",
        "y_train=train_df.iloc[:,-1]\n",
        "\n",
        "X_test=test_df.iloc[:,:-1]\n",
        "y_test=test_df.iloc[:,-1]"
      ],
      "metadata": {
        "id": "gHr-JEwzrY-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train.to_numpy()\n",
        "y_train=y_train.to_numpy()\n",
        "\n",
        "X_test=X_test.to_numpy()\n",
        "y_test=y_test.to_numpy()"
      ],
      "metadata": {
        "id": "4izO7Ur3srfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "onehot_encoder = OneHotEncoder(categories=[np.arange(40)],sparse_output=False)\n",
        "y_train_onehot=onehot_encoder.fit_transform(np.array(y_train).reshape(-1,1))\n",
        "y_test_onehot=onehot_encoder.transform(np.array(y_test).reshape(-1,1))"
      ],
      "metadata": {
        "id": "bNDvKsQ3uoPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.F1Score(name='F1_score',average='micro')\n",
        "]"
      ],
      "metadata": {
        "id": "gOm7uST7ymka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_ANN=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256,input_shape=(X_train.shape[1],),activation='relu'),\n",
        "    tf.keras.layers.Dense(128,activation='relu'),\n",
        "    tf.keras.layers.Dense(40,activation='softmax'),\n",
        "],name=\"ANN_model\")\n",
        "\n",
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.F1Score(name='F1_score',average='micro')\n",
        "]\n",
        "\n",
        "model_ANN.compile(optimizer='adam',loss='categorical_crossentropy',metrics=METRICS)\n",
        "log_dir = \"logs/fit/\" + model_ANN.name+\"-\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "model_ANN.fit(X_train,y_train_onehot,epochs=3,batch_size=128,validation_data=(X_test,y_test_onehot),callbacks=[tensorboard_callback])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coFNT3oktins",
        "outputId": "0771d1d2-6648-4186-97a2-49eac2fab608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "38/38 [==============================] - 3s 17ms/step - loss: 3.1324 - accuracy: 0.9765 - F1_score: 0.2704 - val_loss: 3.1164 - val_accuracy: 0.9747 - val_F1_score: 0.2050\n",
            "Epoch 2/3\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 2.2589 - accuracy: 0.9794 - F1_score: 0.4116 - val_loss: 2.7147 - val_accuracy: 0.9742 - val_F1_score: 0.3010\n",
            "Epoch 3/3\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.9104 - accuracy: 0.9795 - F1_score: 0.4785 - val_loss: 2.4459 - val_accuracy: 0.9733 - val_F1_score: 0.3340\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7aa75965b670>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ANN_dropout=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.4),  # Increase dropout rate\n",
        "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.4),  # Increase dropout rate\n",
        "    tf.keras.layers.Dense(40, activation='softmax')\n",
        "])\n",
        "model_ANN_dropout.compile(optimizer='adam',loss='categorical_crossentropy',metrics=METRICS)\n",
        "model_ANN_dropout.fit(X_train,y_train_onehot,epochs=10,batch_size=16,validation_data=(X_test,y_test_onehot))"
      ],
      "metadata": {
        "id": "C1oJBtpj1CQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ANN_improved = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.6),\n",
        "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(40, activation='softmax')\n",
        "])\n",
        "\n",
        "initial_learning_rate = 0.001\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=10000, decay_rate=0.9, staircase=True\n",
        ")\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "model_ANN_improved.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=METRICS)\n",
        "\n",
        "model_ANN_improved.fit(X_train,y_train_onehot,epochs=5,batch_size=32,validation_data=(X_test,y_test_onehot),callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXuYGP8B2gDQ",
        "outputId": "df57f6a3-7c3d-4c15-c860-8cd27fc01738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "152/152 [==============================] - 4s 9ms/step - loss: 8.7632 - accuracy: 0.9761 - F1_score: 0.2396 - val_loss: 7.9005 - val_accuracy: 0.9750 - val_F1_score: 0.2060\n",
            "Epoch 2/5\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 6.5511 - accuracy: 0.9785 - F1_score: 0.3995 - val_loss: 6.4431 - val_accuracy: 0.9750 - val_F1_score: 0.2590\n",
            "Epoch 3/5\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 5.2032 - accuracy: 0.9788 - F1_score: 0.4410 - val_loss: 5.2043 - val_accuracy: 0.9750 - val_F1_score: 0.3120\n",
            "Epoch 4/5\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 4.2293 - accuracy: 0.9788 - F1_score: 0.4606 - val_loss: 4.2593 - val_accuracy: 0.9745 - val_F1_score: 0.3360\n",
            "Epoch 5/5\n",
            "152/152 [==============================] - 1s 7ms/step - loss: 3.5359 - accuracy: 0.9788 - F1_score: 0.4709 - val_loss: 3.5936 - val_accuracy: 0.9739 - val_F1_score: 0.3470\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7aa560975c00>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "vxPuNSLc81tU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)"
      ],
      "metadata": {
        "id": "l4uutPx7A_oU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled=scaler.transform(X_train)\n",
        "X_test_scaled=scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "9iZOUhh2CdEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=15, kernel_size=8, input_shape=(473, 1)),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2, padding='valid'),\n",
        "    tf.keras.layers.Dropout(0.5),  # Add dropout after pooling\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.Dense(40, activation=\"softmax\")\n",
        "], name=\"CNN_model\")\n",
        "\n",
        "model_CNN.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.experimental.Adamax(), metrics=METRICS)\n",
        "\n",
        "# Implementing early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "model_CNN.fit(X_train, y_train_onehot, epochs=20, validation_data=(X_test, y_test_onehot), callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qakkX0IM6D5K",
        "outputId": "e22e2e0b-983b-4c10-8bda-27635a19831f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "152/152 [==============================] - 2s 5ms/step - loss: 3.2623 - accuracy: 0.9750 - F1_score: 0.2911 - val_loss: 3.2740 - val_accuracy: 0.9750 - val_F1_score: 0.2040\n",
            "Epoch 2/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.7457 - accuracy: 0.9760 - F1_score: 0.3549 - val_loss: 3.2242 - val_accuracy: 0.9749 - val_F1_score: 0.2060\n",
            "Epoch 3/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.6069 - accuracy: 0.9783 - F1_score: 0.3607 - val_loss: 3.1428 - val_accuracy: 0.9750 - val_F1_score: 0.2070\n",
            "Epoch 4/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.5181 - accuracy: 0.9789 - F1_score: 0.3687 - val_loss: 3.0775 - val_accuracy: 0.9749 - val_F1_score: 0.2080\n",
            "Epoch 5/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.4512 - accuracy: 0.9791 - F1_score: 0.3741 - val_loss: 3.0654 - val_accuracy: 0.9748 - val_F1_score: 0.2070\n",
            "Epoch 6/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.3948 - accuracy: 0.9793 - F1_score: 0.3887 - val_loss: 2.9872 - val_accuracy: 0.9749 - val_F1_score: 0.2130\n",
            "Epoch 7/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.3403 - accuracy: 0.9794 - F1_score: 0.3937 - val_loss: 2.9654 - val_accuracy: 0.9749 - val_F1_score: 0.2220\n",
            "Epoch 8/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.2903 - accuracy: 0.9794 - F1_score: 0.4172 - val_loss: 2.9198 - val_accuracy: 0.9749 - val_F1_score: 0.2770\n",
            "Epoch 9/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.2507 - accuracy: 0.9794 - F1_score: 0.4304 - val_loss: 2.8770 - val_accuracy: 0.9749 - val_F1_score: 0.3010\n",
            "Epoch 10/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.2017 - accuracy: 0.9795 - F1_score: 0.4389 - val_loss: 2.8276 - val_accuracy: 0.9748 - val_F1_score: 0.3080\n",
            "Epoch 11/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.1697 - accuracy: 0.9794 - F1_score: 0.4519 - val_loss: 2.7838 - val_accuracy: 0.9747 - val_F1_score: 0.3180\n",
            "Epoch 12/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.1357 - accuracy: 0.9794 - F1_score: 0.4591 - val_loss: 2.7497 - val_accuracy: 0.9746 - val_F1_score: 0.3200\n",
            "Epoch 13/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.0932 - accuracy: 0.9793 - F1_score: 0.4622 - val_loss: 2.7202 - val_accuracy: 0.9746 - val_F1_score: 0.3180\n",
            "Epoch 14/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.0566 - accuracy: 0.9796 - F1_score: 0.4676 - val_loss: 2.6815 - val_accuracy: 0.9744 - val_F1_score: 0.3270\n",
            "Epoch 15/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.0235 - accuracy: 0.9795 - F1_score: 0.4709 - val_loss: 2.6527 - val_accuracy: 0.9743 - val_F1_score: 0.3300\n",
            "Epoch 16/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.9953 - accuracy: 0.9795 - F1_score: 0.4781 - val_loss: 2.6297 - val_accuracy: 0.9744 - val_F1_score: 0.3220\n",
            "Epoch 17/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.9632 - accuracy: 0.9794 - F1_score: 0.4903 - val_loss: 2.5969 - val_accuracy: 0.9742 - val_F1_score: 0.3400\n",
            "Epoch 18/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.9358 - accuracy: 0.9795 - F1_score: 0.4876 - val_loss: 2.5722 - val_accuracy: 0.9739 - val_F1_score: 0.3330\n",
            "Epoch 19/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.9085 - accuracy: 0.9797 - F1_score: 0.4905 - val_loss: 2.5645 - val_accuracy: 0.9741 - val_F1_score: 0.3370\n",
            "Epoch 20/20\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.8876 - accuracy: 0.9795 - F1_score: 0.4930 - val_loss: 2.5304 - val_accuracy: 0.9737 - val_F1_score: 0.3340\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7aa5925f98d0>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_Deep_LSTM = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(64, input_shape=(473, 1), return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.LSTM(16),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.Dense(40, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "], name=\"Improved_Deep_LSTM_model\")\n",
        "\n",
        "model_Deep_LSTM.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=\"adam\", metrics=METRICS)\n",
        "\n",
        "model_Deep_LSTM.fit(X_train, y_train_onehot, epochs=20, batch_size=64, validation_data=(X_test, y_test_onehot),)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca7z0dqX-f_W",
        "outputId": "ca986db7-911c-4244-8614-59fb8ae4f06c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "76/76 [==============================] - 11s 59ms/step - loss: 4.0101 - accuracy: 0.9750 - F1_score: 0.0743 - val_loss: 3.7591 - val_accuracy: 0.9750 - val_F1_score: 0.0030\n",
            "Epoch 2/20\n",
            "76/76 [==============================] - 3s 44ms/step - loss: 3.7498 - accuracy: 0.9750 - F1_score: 0.0820 - val_loss: 3.6338 - val_accuracy: 0.9750 - val_F1_score: 0.0030\n",
            "Epoch 3/20\n",
            "76/76 [==============================] - 3s 43ms/step - loss: 3.5229 - accuracy: 0.9750 - F1_score: 0.1536 - val_loss: 3.5286 - val_accuracy: 0.9750 - val_F1_score: 0.0030\n",
            "Epoch 4/20\n",
            "76/76 [==============================] - 3s 44ms/step - loss: 3.3193 - accuracy: 0.9750 - F1_score: 0.2027 - val_loss: 3.4232 - val_accuracy: 0.9750 - val_F1_score: 0.0450\n",
            "Epoch 5/20\n",
            "76/76 [==============================] - 3s 43ms/step - loss: 3.1889 - accuracy: 0.9750 - F1_score: 0.2124 - val_loss: 3.3167 - val_accuracy: 0.9750 - val_F1_score: 0.2060\n",
            "Epoch 6/20\n",
            "76/76 [==============================] - 3s 43ms/step - loss: 3.1537 - accuracy: 0.9750 - F1_score: 0.1761 - val_loss: 3.2369 - val_accuracy: 0.9750 - val_F1_score: 0.2060\n",
            "Epoch 7/20\n",
            "76/76 [==============================] - 3s 43ms/step - loss: 3.0705 - accuracy: 0.9749 - F1_score: 0.1769 - val_loss: 3.2634 - val_accuracy: 0.9750 - val_F1_score: 0.2060\n",
            "Epoch 8/20\n",
            "76/76 [==============================] - 3s 44ms/step - loss: 3.0061 - accuracy: 0.9750 - F1_score: 0.1800 - val_loss: 3.3214 - val_accuracy: 0.9750 - val_F1_score: 0.0030\n",
            "Epoch 9/20\n",
            "76/76 [==============================] - 3s 43ms/step - loss: 2.9738 - accuracy: 0.9750 - F1_score: 0.1910 - val_loss: 3.2483 - val_accuracy: 0.9750 - val_F1_score: 0.2060\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x798b27f69780>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_BiLSTM = tf.keras.Sequential([\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True), input_shape=(473, 1)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "\n",
        "\n",
        "    tf.keras.layers.Dense(40, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "], name=\"BiLSTM_model\")\n",
        "\n",
        "model_BiLSTM.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=\"adam\", metrics=METRICS)\n",
        "\n",
        "model_BiLSTM.fit(X_train, y_train_onehot, epochs=20, batch_size=32, validation_data=(X_test, y_test_onehot))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvpTv3kGXQVw",
        "outputId": "dcb3bf92-960e-4bcc-839a-e4ebfb9b1b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "152/152 [==============================] - 16s 69ms/step - loss: 3.2976 - accuracy: 0.9747 - F1_score: 0.2337 - val_loss: 3.3469 - val_accuracy: 0.9746 - val_F1_score: 0.1590\n",
            "Epoch 2/20\n",
            "152/152 [==============================] - 9s 59ms/step - loss: 2.7644 - accuracy: 0.9748 - F1_score: 0.3371 - val_loss: 3.0013 - val_accuracy: 0.9750 - val_F1_score: 0.2220\n",
            "Epoch 3/20\n",
            "152/152 [==============================] - 9s 60ms/step - loss: 2.5707 - accuracy: 0.9755 - F1_score: 0.3759 - val_loss: 2.9325 - val_accuracy: 0.9730 - val_F1_score: 0.2890\n",
            "Epoch 4/20\n",
            "152/152 [==============================] - 9s 60ms/step - loss: 2.4207 - accuracy: 0.9768 - F1_score: 0.4139 - val_loss: 2.8044 - val_accuracy: 0.9733 - val_F1_score: 0.2990\n",
            "Epoch 5/20\n",
            "152/152 [==============================] - 9s 59ms/step - loss: 2.3376 - accuracy: 0.9770 - F1_score: 0.4321 - val_loss: 2.8388 - val_accuracy: 0.9725 - val_F1_score: 0.2670\n",
            "Epoch 6/20\n",
            "152/152 [==============================] - 9s 60ms/step - loss: 2.2582 - accuracy: 0.9776 - F1_score: 0.4422 - val_loss: 2.7424 - val_accuracy: 0.9719 - val_F1_score: 0.3070\n",
            "Epoch 7/20\n",
            "152/152 [==============================] - 9s 59ms/step - loss: 2.2043 - accuracy: 0.9777 - F1_score: 0.4459 - val_loss: 2.7277 - val_accuracy: 0.9721 - val_F1_score: 0.3010\n",
            "Epoch 8/20\n",
            "152/152 [==============================] - 9s 59ms/step - loss: 2.1823 - accuracy: 0.9778 - F1_score: 0.4368 - val_loss: 2.6918 - val_accuracy: 0.9722 - val_F1_score: 0.3090\n",
            "Epoch 9/20\n",
            "152/152 [==============================] - 9s 60ms/step - loss: 2.1404 - accuracy: 0.9778 - F1_score: 0.4517 - val_loss: 2.6131 - val_accuracy: 0.9732 - val_F1_score: 0.3300\n",
            "Epoch 10/20\n",
            "152/152 [==============================] - 9s 59ms/step - loss: 2.1117 - accuracy: 0.9779 - F1_score: 0.4523 - val_loss: 2.5674 - val_accuracy: 0.9738 - val_F1_score: 0.3280\n",
            "Epoch 11/20\n",
            "152/152 [==============================] - 9s 59ms/step - loss: 2.0719 - accuracy: 0.9781 - F1_score: 0.4606 - val_loss: 2.5484 - val_accuracy: 0.9740 - val_F1_score: 0.3290\n",
            "Epoch 12/20\n",
            "152/152 [==============================] - 9s 60ms/step - loss: 2.0730 - accuracy: 0.9781 - F1_score: 0.4529 - val_loss: 2.6085 - val_accuracy: 0.9738 - val_F1_score: 0.3320\n",
            "Epoch 13/20\n",
            "152/152 [==============================] - 9s 59ms/step - loss: 2.0607 - accuracy: 0.9783 - F1_score: 0.4569 - val_loss: 2.5772 - val_accuracy: 0.9727 - val_F1_score: 0.3240\n",
            "Epoch 14/20\n",
            "152/152 [==============================] - 9s 59ms/step - loss: 2.0222 - accuracy: 0.9782 - F1_score: 0.4575 - val_loss: 2.5141 - val_accuracy: 0.9732 - val_F1_score: 0.3410\n",
            "Epoch 15/20\n",
            "152/152 [==============================] - 9s 60ms/step - loss: 1.9867 - accuracy: 0.9783 - F1_score: 0.4711 - val_loss: 2.4922 - val_accuracy: 0.9737 - val_F1_score: 0.3470\n",
            "Epoch 16/20\n",
            "152/152 [==============================] - 9s 59ms/step - loss: 2.1856 - accuracy: 0.9773 - F1_score: 0.4397 - val_loss: 2.6892 - val_accuracy: 0.9725 - val_F1_score: 0.3240\n",
            "Epoch 17/20\n",
            "152/152 [==============================] - 9s 60ms/step - loss: 2.1149 - accuracy: 0.9778 - F1_score: 0.4536 - val_loss: 2.5894 - val_accuracy: 0.9735 - val_F1_score: 0.3280\n",
            "Epoch 18/20\n",
            "152/152 [==============================] - 9s 60ms/step - loss: 2.0549 - accuracy: 0.9781 - F1_score: 0.4556 - val_loss: 2.5470 - val_accuracy: 0.9734 - val_F1_score: 0.3330\n",
            "Epoch 19/20\n",
            "152/152 [==============================] - 9s 60ms/step - loss: 2.0344 - accuracy: 0.9781 - F1_score: 0.4618 - val_loss: 2.5092 - val_accuracy: 0.9728 - val_F1_score: 0.3360\n",
            "Epoch 20/20\n",
            "152/152 [==============================] - 9s 60ms/step - loss: 2.0014 - accuracy: 0.9783 - F1_score: 0.4604 - val_loss: 2.4912 - val_accuracy: 0.9736 - val_F1_score: 0.3420\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x798b09d1e4a0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class Attention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(Attention, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "        # Initialize weight matrices\n",
        "        self.W_q = tf.keras.layers.Dense(units)\n",
        "        self.W_k = tf.keras.layers.Dense(units)\n",
        "        self.W_v = tf.keras.layers.Dense(units)\n",
        "\n",
        "        self.scale = tf.keras.layers.Lambda(lambda x: x / tf.math.sqrt(tf.cast(units, tf.float32)))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        query, key, value = inputs\n",
        "\n",
        "        # Process inputs through weight matrices\n",
        "        query = self.W_q(query)\n",
        "        key = self.W_k(key)\n",
        "        value = self.W_v(value)\n",
        "\n",
        "        # Calculate attention scores\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        score = self.scale(score)\n",
        "        attention_weights = tf.nn.softmax(score, axis=-1)\n",
        "\n",
        "        # Apply attention weights to value\n",
        "        output = tf.matmul(attention_weights, value)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "# Define the BiLSTM model with Attention\n",
        "input_layer = tf.keras.Input(shape=(473, 1))\n",
        "lstm_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(input_layer)\n",
        "lstm_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(lstm_1)\n",
        "\n",
        "attention_output = Attention(32)([lstm_2, lstm_2, lstm_2])  # Pass the same input to all attention components\n",
        "\n",
        "concatenate=tf.keras.layers.Concatenate(axis=1)([attention_output])\n",
        "\n",
        "output_layer = tf.keras.layers.Dense(40, activation=\"softmax\")(concatenate)\n",
        "\n",
        "\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "\n",
        "# model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=\"adam\", metrics=METRICS)\n",
        "# model.fit(X_train, y_train_onehot, epochs=20, batch_size=32, validation_data=(X_test, y_test_onehot))\n"
      ],
      "metadata": {
        "id": "a6NKWokjZseJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=\"adam\", metrics=METRICS)"
      ],
      "metadata": {
        "id": "dsyEMkFkdzIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vddVEyZ5fexl",
        "outputId": "e5c5f246-c4a9-4aa3-9f68-7a86715c7583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_16 (InputLayer)       [(None, 473, 1)]             0         []                            \n",
            "                                                                                                  \n",
            " bidirectional_52 (Bidirect  (None, 473, 256)             133120    ['input_16[0][0]']            \n",
            " ional)                                                                                           \n",
            "                                                                                                  \n",
            " bidirectional_53 (Bidirect  (None, 473, 128)             164352    ['bidirectional_52[0][0]']    \n",
            " ional)                                                                                           \n",
            "                                                                                                  \n",
            " attention_20 (Attention)    (None, 473, 32)              12384     ['bidirectional_53[0][0]',    \n",
            "                                                                     'bidirectional_53[0][0]',    \n",
            "                                                                     'bidirectional_53[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 473, 32)              0         ['attention_20[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_101 (Dense)           (None, 473, 40)              1320      ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 311176 (1.19 MB)\n",
            "Trainable params: 311176 (1.19 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train_onehot, epochs=20, batch_size=32, validation_data=(X_test, y_test_onehot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "D_MNq07GfRVY",
        "outputId": "10a61de1-8e22-4d94-c574-7a9ec87e37d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "152/152 [==============================] - 25s 101ms/step - loss: 3.0022 - accuracy: 0.9750 - F1_score: 0.1453 - val_loss: 3.2844 - val_accuracy: 0.9750 - val_F1_score: 0.2060\n",
            "Epoch 2/20\n",
            "152/152 [==============================] - 13s 88ms/step - loss: 2.8803 - accuracy: 0.9750 - F1_score: 0.1879 - val_loss: 3.2556 - val_accuracy: 0.9750 - val_F1_score: 0.2060\n",
            "Epoch 3/20\n",
            " 58/152 [==========>...................] - ETA: 7s - loss: 2.8164 - accuracy: 0.9750 - F1_score: 0.2398"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-1316f708dc10>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning models"
      ],
      "metadata": {
        "id": "40SKxwAjj6gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "svm_classifier = SVC(kernel='linear', decision_function_shape='ovr')  # Using a linear kernel for example\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = svm_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy and F1 score\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "f1_score_micro = f1_score(y_test, predictions, average='micro')\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%, F1 Score (micro): {f1_score_micro * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbyOhY70klLr",
        "outputId": "80fdce8a-4ed4-4ba3-84c9-e18955ee842d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 31.60%, F1 Score (micro): 31.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "554o_DoWn6Oc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}