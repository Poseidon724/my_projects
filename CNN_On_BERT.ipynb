{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ba5R8Av6DAwb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7572060-c55c-49ab-fc32-542826b6e3de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text"
      ],
      "metadata": {
        "id": "px-N17zKsLcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "082affc4-e39f-44aa-d0f4-c91e31f96c82"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tensorflow_text in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.15.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.2.2)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ],
      "metadata": {
        "id": "4FzeHRHisIcG",
        "outputId": "284d3ffd-9b00-4413-cba5-fb5ed58873ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-566f9fbfe6f7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_text\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m             present=tf.__version__))\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0m_ensure_tf_install\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/__init__.py\u001b[0m in \u001b[0;36m_ensure_tf_install\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0mrequired_tensorflow_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1.15.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m   if (parse_version(tf.__version__) <\n\u001b[0m\u001b[1;32m     75\u001b[0m       parse_version(required_tensorflow_version)):\n\u001b[1;32m     76\u001b[0m     raise ImportError(\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute '__version__'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./logs/"
      ],
      "metadata": {
        "id": "mBj3zKCIXejz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import pandas as pd\n",
        "data=pd.read_csv('gdrive/My Drive/oversampled_data.csv')\n",
        "data=data.drop([data.columns[0]],axis=1)"
      ],
      "metadata": {
        "id": "Y7258fKsL2Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "XuUkJRXNGKUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['medical_specialty'].value_counts()"
      ],
      "metadata": {
        "id": "1HLSKwN6LFTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data[['description','keywords']]=data[['description','keywords']].fillna(\"none\")"
      ],
      "metadata": {
        "id": "st6knnukGLc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using only transcription as a feature for classification"
      ],
      "metadata": {
        "id": "u7a0QoIMLT9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transcript=data[['transcription','medical_specialty']]"
      ],
      "metadata": {
        "id": "2pBbydNmLJyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transcript"
      ],
      "metadata": {
        "id": "tkdgxrz-L-WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "qd_7lXjpMEYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=data_transcript.iloc[:,0]\n",
        "Y=data_transcript.iloc[:,-1]"
      ],
      "metadata": {
        "id": "3jtJI0wwO0Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,Y,shuffle=True,test_size=0.2)"
      ],
      "metadata": {
        "id": "sUHezyBgOCmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_sentences=X_train.to_list()\n",
        "testing_sentences=X_test.to_list()\n",
        "training_labels=y_train.to_list()\n",
        "testing_labels=y_test.to_list()"
      ],
      "metadata": {
        "id": "Cd8dwXjMOr8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False, categories='auto')\n",
        "training_labels_final=encoder.fit_transform(np.array(training_labels).reshape(-1,1))\n",
        "testing_labels_final=encoder.transform(np.array(testing_labels).reshape(-1,1))"
      ],
      "metadata": {
        "id": "rvmv_N-PM542"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess = hub.KerasLayer(\"https://kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3\",trainable=False)\n",
        "# bert_encoder = hub.KerasLayer(\"https://tfhub.dev/google/LaBSE/2\",trainable=False)\n",
        "bert_encoder = hub.KerasLayer(\"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/bert-en-uncased-l-10-h-128-a-2/versions/2\",trainable=False)"
      ],
      "metadata": {
        "id": "4LcOcmxgq6zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')"
      ],
      "metadata": {
        "id": "3U9A2tUvy5qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_text = bert_preprocess(text_input)"
      ],
      "metadata": {
        "id": "r4gEmcs3_UdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_outputs = bert_encoder(preprocessed_text)"
      ],
      "metadata": {
        "id": "38VMkksc_YKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bert_outputs = np.array(bert_outputs)\n",
        "# bert_outputs.shape\n",
        "bert_outputs"
      ],
      "metadata": {
        "id": "5WIb9poCF3s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "# l = tf.keras.layers.Dense(200,activation = 'Sigmoid')\n",
        "# l = tf.keras.layers.Dense(40, activation='softmax', name=\"output\")(l)\n",
        "# l_input = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "# l1 = tf.keras.layers.Dense(1000, activation='relu')(l_input)  # Specify the input tensor (l) for the Dense layer\n",
        "# l2 = tf.keras.layers.Dense(200, activation='relu')(l1)\n",
        "# l_output = tf.keras.layers.Dense(40, activation='softmax', name=\"output\")(l2)\n",
        "\n",
        "\n",
        "\n",
        "# l_input = tf.keras.layers.Dropout(0.1, name=\"dropout\")(bert_outputs['pooled_output'])\n",
        "# # l_input = tf.keras.layers.Reshape(target_shape=(768, 1))(l_input)\n",
        "# l_input = tf.keras.layers.Reshape(target_shape=(128, 1))(l_input)\n",
        "# print(l_input.shape)\n",
        "# l1 = tf.keras.layers.Conv1D(500, 7,activation='relu')(l_input)\n",
        "# l2 = tf.keras.layers.MaxPooling1D(5)(l1)\n",
        "\n",
        "# l3 = tf.keras.layers.Conv1D(200, 15,activation='relu')(l2)\n",
        "# l4 = tf.keras.layers.GlobalMaxPooling1D()(l3)\n",
        "\n",
        "# l_output = tf.keras.layers.Dense(40, activation='softmax', name=\"output\")(l4)\n",
        "\n",
        "\n",
        "\n",
        "#REGULARIZED\n",
        "# l_input = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "# l1 = tf.keras.layers.Conv1D(5000, 7,activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(l_input)\n",
        "# l2 = tf.keras.layers.MaxPooling1D(5)(l1)\n",
        "\n",
        "# l3 = tf.keras.layers.Conv1D(200, 15,activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(l2)\n",
        "# l4 = tf.keras.layers.GlobalMaxPooling1D()(l3)\n",
        "\n",
        "# l_output = tf.keras.layers.Dense(40, activation='softmax', name=\"output\")(l4)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IrewwJvH_bAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #CNN\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dropout,Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "# from keras.layers import Embedding\n",
        "# max_words = 20000\n",
        "# max_length = 500\n",
        "\n",
        "# model = Sequential()\n",
        "# # l_input = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "# # l1 = tf.keras.layers.Dense(1000, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "# # l2 = tf.keras.layers.Dense(200, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))\n",
        "\n",
        "# # l_output = tf.keras.layers.Dense(40, activation='softmax', name=\"output\")\n",
        "# model.add(Embedding(max_words, 32, input_length=max_length))\n",
        "# model.add(Dropout(0.1, name=\"dropout\"))\n",
        "# model.add(Conv1D(32, 7, activation='relu'))\n",
        "# model.add(MaxPooling1D(5))\n",
        "# model.add(Conv1D(32, 7, activation='relu'))\n",
        "# model.add(GlobalMaxPooling1D())\n",
        "# model.add(Dense(40, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# # model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Pz2KoQJN4iBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# last_layer_output = model.layers[-1].output\n",
        "# model = tf.keras.Model(inputs=[text_input], outputs = [l_output])\n",
        "# model = tf.keras.Model(inputs=[text_input])\n",
        "\n",
        "\n",
        "# model = tf.keras.Model(inputs=[bert_outputs], outputs = [l_output])"
      ],
      "metadata": {
        "id": "w_Y1J1uz_eDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.summary()"
      ],
      "metadata": {
        "id": "W8dKtAoOAW0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Metrics**"
      ],
      "metadata": {
        "id": "-uwZwv8nTnsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# METRICS = [\n",
        "#       tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "#       tf.keras.metrics.Precision(name='precision'),\n",
        "#       tf.keras.metrics.F1Score(name='F1_score',average='micro')\n",
        "# ]\n",
        "\n",
        "# model.compile(optimizer='adam',\n",
        "#  loss='categorical_crossentropy',\n",
        "#  metrics=METRICS)"
      ],
      "metadata": {
        "id": "cStqijlBAYhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "dCKmOg6MCpJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import confusion_matrix\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n"
      ],
      "metadata": {
        "id": "ji2S-o5X0fPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hist = model.fit(X_train, training_labels_final, epochs=1,validation_data=(X_test,testing_labels_final))"
      ],
      "metadata": {
        "id": "KZggPlr4VHKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions = model.predict(X_test)\n",
        "# predicted_labels = tf.argmax(predictions,axis=1)\n",
        "# true_labels = tf.argmax(testing_labels_final, axis=1)\n",
        "# cm = tf.math.confusion_matrix(true_labels, predicted_labels)\n"
      ],
      "metadata": {
        "id": "Fy6jEOD30fMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# categories = ['Class 0', 'Class 1', 'Class 2']  # Replace with your class labels\n",
        "\n",
        "# categories = data['medical_speciality']\n",
        "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
        "# plt.xlabel('Predicted Labels')\n",
        "# plt.ylabel('True Labels')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "uK925f1y0fJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "# sns.set()\n",
        "\n",
        "# acc = hist.history['accuracy']\n",
        "# val = hist.history['val_accuracy']\n",
        "# epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# plt.plot(epochs, acc, '-', label='Training accuracy')\n",
        "# plt.plot(epochs, val, ':', label='Validation accuracy')\n",
        "# plt.title('Training and Validation Accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.legend(loc='lower right')\n",
        "# plt.plot()"
      ],
      "metadata": {
        "id": "3HA3_9BeAkaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_H_2P7dddDAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XtNhKNN4dC9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lsIjXqjudC66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "53b6_vocdC4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gOQ57uFodC2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ELlzxmimdC0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load the BERT preprocess module\n",
        "bert_preprocess = hub.KerasLayer(\"https://kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3\",trainable=False)\n",
        "# bert_encoder = hub.KerasLayer(\"https://tfhub.dev/google/LaBSE/2\",trainable=False)\n",
        "bert_encoder = hub.KerasLayer(\"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/bert-en-uncased-l-10-h-128-a-2/versions/2\",trainable=False)"
      ],
      "metadata": {
        "id": "M3Khc5Z7bPjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input layer\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "\n",
        "# Preprocess the text using the BERT preprocess module\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "\n",
        "# Pass the preprocessed text through the BERT encoder\n",
        "bert_outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "# Apply dropout and reshape the output\n",
        "l_input = tf.keras.layers.Dropout(0.1, name=\"dropout\")(bert_outputs['pooled_output'])\n",
        "l_input = tf.keras.layers.Reshape(target_shape=(128,))(l_input)\n",
        "\n",
        "# Convolutional layers\n",
        "l1 = tf.keras.layers.Conv1D(500, 7, activation='relu')(l_input)\n",
        "l2 = tf.keras.layers.MaxPooling1D(5)(l1)\n",
        "l3 = tf.keras.layers.Conv1D(200, 15, activation='relu')(l2)\n",
        "l4 = tf.keras.layers.GlobalMaxPooling1D()(l3)\n",
        "\n",
        "# Output layer\n",
        "l_output = tf.keras.layers.Dense(40, activation='softmax', name=\"output\")(l4)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Model(inputs=[text_input], outputs=[l_output])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "eHx-bqyfbPgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.F1Score(name='F1_score',average='micro')\n",
        "]\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        " loss='categorical_crossentropy',\n",
        " metrics=METRICS)"
      ],
      "metadata": {
        "id": "2zqIw2_pbPd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "EzBNVXIRbiVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "Uzs2cuuBbiNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " hist = model.fit(X_train, training_labels_final, epochs=1,validation_data=(X_test,testing_labels_final))"
      ],
      "metadata": {
        "id": "tOArb8QlbiK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "predicted_labels = tf.argmax(predictions,axis=1)\n",
        "true_labels = tf.argmax(testing_labels_final, axis=1)\n",
        "cm = tf.math.confusion_matrix(true_labels, predicted_labels)"
      ],
      "metadata": {
        "id": "4i2zA2tVeudI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "sns.set()\n",
        "\n",
        "acc = hist.history['accuracy']\n",
        "val = hist.history['val_accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, '-', label='Training accuracy')\n",
        "plt.plot(epochs, val, ':', label='Validation accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "jtuRfJWIdsPT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}